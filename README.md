# TopTrade

TopTrade is a machine leaning system that aims to predict whether a certain cryptocurrency is a buy or a sell over a specified trading period. For the purpose of this project, the cryptocurrencies that I will be focusing on are Bitcoin, Ethereum, Litecoin and Bitcoin Cash because they are among the most prominent cryptocurrencies. This project includes data wrangling, data visalization, feature engineering, preprocessing data, generating models and hyperparameter tuning. The following document will outline the high level approaches I have taken to develop this project. 

## Introduction
### Data
The data in this project was sourced from the Poloniex API. The Poloniex API gives access to data from the most popular cryptocurrencies, including the ones that I will be using, at a variety of granularities. For each of the four cryptocurrencies we are interested in the close and the volume values at the minute level. The close is the cryptocurrencies market price at the end of the minute interval and the volume is the amount of units that were exchanged during the minute interval. Below is initial structure of the data as described above: 

<img width="672" alt="Screen Shot 2020-01-07 at 10 10 23 PM" src="https://user-images.githubusercontent.com/34798787/71947517-1f1e6900-319b-11ea-960d-d607dd76753b.png">

### Features 
With the goal of flexibilty in mind, I would like the ability to dynamically change the cryptocurrency that will predicted. This means that the preliminary set of features that the underlying model will use to generate the predictions will consist of the historical values of the volume of the cryptocurrency being predicted along with the historical values of the volume and close of the remaining three cryptocurrencies. It is my hope that this set of features will offer insight into the price movement of the target cryptocurrency. The high level hypothesis I am making is that the prices and volumes of cryptocurrencies are related in some way. In order to test this assumption, I looked into how the prices of the various cryptocurrencies are correlated. This was done by taking the original dataset and selecting only columns corresponding to cryptocurrencies prices (4 in total). I then normalized this data by taking the percentage change between subsequent values in each columns. The pearson correlation coefficitents were then calculated between the cryptocurrencies. An illustrustion of the aforementioned analysis is below: 

<img width="368" alt="Screen Shot 2020-01-07 at 5 40 13 PM" src="https://user-images.githubusercontent.com/34798787/71948527-47f42d80-319e-11ea-82f5-9a3725bb2551.png">

As evidenced by the values of the pearson correlation coeficients exceeding .5, there is some degree of relationship between the price movement of the various cryptocurrencies. This relationship can potentially be exploited by a model to predict whether a cryptocurrency is a buy or a sell over a specified trading period. 

### Feature Engineering
Based on our existing features, I will derive additional potentially insightful features. This process is known as feature engineering. In particular, I will be creating features based on the price movement of the target cryptocurrency referred to as technical indicators. Technical indicators are a mathematical calculation based on historic price, or other related information, that aims to forecast the direction of the price of an asset. Below is a list of technical indicators that were derived: 

- **7 Interval Moving Average:** The average of the prices over the last 7 intervals.
- **21 Interval Moving Average:** The average of the prices over the last 21 intervals.
- **12 Interval Exponential Moving Average:** The average of the prices over the last 12 intervals with more wighting to more recent prices. 
- **26 Interval Exponential Moving Average:** The average of the prices over the last 26 intervals with more weighting to more recent prices. 
- **20 Interval Standard Deviation:** The standard deviation of the 20 previous intervals. 
- **Bollinger Bands:** A Bollinger Band is a technical analysis tool defined by a set of lines plotted two standard deviations (positively and negatively) away from a simple moving average (SMA) of the price

### Preprocessing 
Now that I have generated a set of meaningful features (X), I will preprocess the data in order to prepare it to be fed into the subsequent model. First the target column (y) is generated. This is done in two stepss. First, the Future column is generate done by shifting price of the target cryptocurrency in the future a specified amount of intervals. By doing so, the Future column represents the price of the target cryptocurrncy a certain amount of periods in the future. The amount of periods in the future to predict can be set dynamically. I have a chosen a seemingly reasnable value of 3. Based off the Future Column, the "y" column is generated by comparing the current price of the target cruptocurrency to the Future column. If the future price is higher then the current price, the y value of the observation is buy (1), otherwise the y values of the observation is a sell (0). The resulting dataset is shown below: 

<img width="559" alt="Screen Shot 2020-01-07 at 11 53 59 PM" src="https://user-images.githubusercontent.com/34798787/71951426-03ba5a80-31a9-11ea-9f2d-aa33cb9cdd70.png">

Following the removal of the Future column, the data is normalized by converting values to percent change over time and scaling the resulting values from 0 to 1 for each column in the dataset except the y column. The y column is also removed from the dataset and stored in its own seperate sequence. Next, the feature dataset is generating by transforming the existing dataset into sequences of observations of a specified length. This length can be set dynamically. I have chosen a seemingly reasonable length of 60. As such, the feature dataset is transformed into a three dimensional matrix where each observation corresponds to sequences of 60 records with 17 columns that represent the features of each record. Accordingly, we have our feature dataset and corresponding target sequence that we will divide into traing and testing sets. As the names imply, the training set will be used to train the model and the testing sets will be used to test the model. 

## Model 
### Model Information
When selecting the model to generate the predictions, it is important to consider the nature of the data we are modelling. It is clear the data is functional in the sense that it takes place over the dimension of time. A specific type of deep learning models called Recurrent Neural Networks. An RNN is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks involving functional data including asset price forecasting. In particular, we be using a Long Short-Term Memory (LSTM), a specific type of RNN. A LSTM Model consists of several LSTM units that facilitate the flow of data through the model. A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. Below is an illustration of a LSTM unit: 

![The_LSTM_cell](https://user-images.githubusercontent.com/34798787/71954598-cdcea380-31b3-11ea-93ab-af83f74e3a25.png)

### Hyperparameter Tuning 
The LSTM model has a number of hyperparameters that dictate the architecture and other high level information about the model. In order to generate the best model possible, I will try different permutations of the hyperparameters and select the model with the best performance. Due to the intensive nature of the computation involved with the corresponding grid search for the model's hyperparameters, only a limited number of permutations of model hyperparameters will be evaluated. Below are the three hyperparameters that will be involved in this grid search: 
- **LSTM Layer Units:** The number of nodes in each LSTM layer.
- **Dense Layer Units:** The number of nodes in each dense layer. 
- **LSTM Layers:** The number of LSTM layers in the model. 

## Results 

